import os
import re
import logging
import pymysql
import traceback
from typing import List, Optional, Dict, Any, Tuple
from datetime import datetime
import json

from langchain_community.utilities import SQLDatabase
from langchain_ollama import OllamaLLM
from langchain.chains import create_sql_query_chain

# --- CONFIGURATION ---

DB_CONFIGS = {
    "team": {
        "name": "Team Info",
        "db_config": {
            "host": "localhost", "user": "root", "password": "root123", "database": "EIS"
        },
        "include_tables": ["UserMaster"],
    }
}

# Static token collection for frontend integration
STATIC_TOKENS = {
    "TEAM_QUERY": {
        "category": "team",
        "description": "Query team/user information",
        "examples": ["show employees", "find user details", "list team members"]
    },
    "GENERAL_QUERY": {
        "category": "general",
        "description": "General AI assistance",
        "examples": ["explanations", "help", "technical questions"]
    }
}

logging.basicConfig(
    filename=os.path.expanduser("~/.team_ai.log"),
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def extract_token_and_query(user_input: str) -> Tuple[str, str]:
    """
    Extract static token and actual query from user input
    Expected format: "TOKEN: actual user query"
    """
    if ":" in user_input:
        parts = user_input.split(":", 1)
        if len(parts) == 2:
            token = parts[0].strip().upper()
            query = parts[1].strip()
            return token, query
    return "", user_input

def get_category_from_token(token: str) -> str:
    """
    Map static token to category
    """
    token_mapping = {
        "TEAM_QUERY": "team",
        "GENERAL_QUERY": "general"
    }
    return token_mapping.get(token, "general")

def detect_query_type_fallback(question: str) -> str:
    """
    Fallback detection when no token is provided (for backward compatibility)
    """
    question = question.lower()
    team_patterns = [
        r'\b(team|user|employee|staff|member|person|people)\b',
        r'\b(show|list|find|get|count|search)\b.*\b(employee|user|team|staff)\b',
        r'\b(who|which\s+user|which\s+employee)\b',
        r'\bname.*\b(john|smith|portal|eis|project)\b',
        r'\b(portal|eis|project)\b.*\b(team|user|employee)\b'
    ]
    
    for pattern in team_patterns:
        if re.search(pattern, question):
            return "team"
    
    return "general"

def clean_sql(raw_sql: str) -> str:
    match = re.search(r"```sql\s*(.*?)\s*```", raw_sql, re.DOTALL | re.IGNORECASE)
    if match:
        sql = match.group(1)
    else:
        sql = re.sub(r"```", "", raw_sql)
        sql = re.sub(r"^(.*?)(SELECT|INSERT|UPDATE|DELETE|WITH)", r"\2", sql, flags=re.IGNORECASE | re.DOTALL)
    return sql.strip().rstrip(";")

def format_answer(result: List[tuple], columns: Optional[List[str]] = None) -> str:
    if not result:
        return "No data found for your request."
    if len(result) == 1 and len(result[0]) == 1:
        return f"Result: {result[0][0]}"
    if columns and len(result) <= 10:
        output = []
        col_widths = [max(len(str(col)), max(len(str(row[i])) for row in result)) for i, col in enumerate(columns)]
        header = " | ".join(col.ljust(width) for col, width in zip(columns, col_widths))
        separator = "-+-".join("-" * width for width in col_widths)
        output.append(header)
        output.append(separator)
        for row in result[:10]:
            formatted_row = " | ".join(str(val).ljust(width) for val, width in zip(row, col_widths))
            output.append(formatted_row)
        if len(result) > 10:
            output.append(f"... and {len(result) - 10} more rows")
        return "\n".join(output)
    rows = []
    for row in result[:20]:
        rows.append(" | ".join(str(val) for val in row))
    if len(result) > 20:
        rows.append(f"... and {len(result) - 20} more rows")
    return "\n".join(rows)

def is_select_query(sql: str) -> bool:
    return sql.strip().lower().startswith('select')

def clear_screen():
    os.system("cls" if os.name == "nt" else "clear")

class TeamAIAssistant:
    def __init__(self):
        self.llm = None
        self.db_handlers = {}
        self.initialized = False
        self.chat_history = []

    def initialize(self):
        try:
            print("üîß Initializing Team AI Assistant...")
            self.llm = OllamaLLM(model="mistral:7b-instruct-q4_K_M", temperature=0.1)
            for category, config in DB_CONFIGS.items():
                try:
                    db_cfg = config['db_config']
                    uri = f"mysql+pymysql://{db_cfg['user']}:{db_cfg['password']}@{db_cfg['host']}/{db_cfg['database']}"
                    db_for_llm = SQLDatabase.from_uri(uri, include_tables=config.get("include_tables"))
                    chain = create_sql_query_chain(self.llm, db_for_llm)
                    db_conn = pymysql.connect(**db_cfg)
                    self.db_handlers[category] = {
                        'chain': chain,
                        'connection': db_conn,
                        'config': config
                    }
                    print(f"‚úÖ {config['name']} database connected")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Failed to connect to {config['name']}: {e}")
                    logger.error(f"DB connection failed for {category}: {e}")
            self.initialized = True
            print("‚úÖ Team AI Assistant initialized successfully!")
            return True
        except Exception as e:
            print(f"‚ùå Initialization failed: {e}")
            logger.error(f"Initialization failed: {e}", exc_info=True)
            return False

    def get_available_tokens(self) -> Dict[str, Dict]:
        """
        Return available static tokens for frontend integration
        """
        return STATIC_TOKENS

    def save_feedback(self, question, answer, feedback):
        data = {
            "question": question,
            "answer": answer,
            "feedback": feedback,
            "timestamp": datetime.now().isoformat()
        }
        try:
            with open("feedback_log.jsonl", "a") as f:
                f.write(json.dumps(data) + "\n")
        except Exception as e:
            logger.error(f"Failed to save feedback: {e}")

    def find_relevant_feedback(self, question):
        try:
            with open("feedback_log.jsonl", "r") as f:
                lines = f.readlines()
            for line in lines[::-1]:
                entry = json.loads(line)
                if entry["question"].strip().lower() in question.strip().lower():
                    return entry["feedback"]
        except Exception:
            pass
        return None

    def query_database(self, question: str, category: str) -> str:
        if category not in self.db_handlers:
            return f"‚ùå Database category '{category}' not available."
        
        handler = self.db_handlers[category]
        try:
            raw_sql = handler['chain'].invoke({"question": question})
            sql = clean_sql(raw_sql)
            
            if not is_select_query(sql):
                return "üö´ Only SELECT queries are allowed for security."
            
            with handler['connection'].cursor() as cursor:
                cursor.execute(sql)
                result = cursor.fetchall()
                columns = [desc[0] for desc in cursor.description] if cursor.description else None
            
            if not result:
                return "No data found matching your query."
            
            formatted_result = format_answer(result, columns)
            context = f"""
Database query executed: {sql}
Results: {formatted_result}

User question: {question}

Please provide a clear, natural language response that directly answers the user's question based on this data. Make it conversational and helpful.
"""
            feedback = self.find_relevant_feedback(question)
            if feedback:
                context += f"\nNote: Previously, a user provided this correction for a similar question: '{feedback}'"
            
            ai_interpretation = self.llm.invoke(context)
            self.chat_history.append({"user": question, "assistant": ai_interpretation})
            return ai_interpretation
        except Exception as e:
            logger.error(f"Database query error: {e}")
            return f"‚ùå Unable to retrieve that information: {e}"

    def general_ai_response(self, question: str) -> str:
        try:
            context = f"""
You are a helpful AI assistant with expertise in team management, databases, and general technical knowledge.

User question: {question}

Please provide a clear, helpful, and accurate response. If this is a technical question, provide practical advice. If it's a general question, be informative and conversational.
"""
            feedback = self.find_relevant_feedback(question)
            if feedback:
                context += f"\nNote: Previously, a user provided this correction for a similar question: '{feedback}'"
            
            response = self.llm.invoke(context)
            self.chat_history.append({"user": question, "assistant": response})
            return response
        except Exception as e:
            logger.error(f"AI response error: {e}")
            return f"‚ùå Unable to process your question: {e}"

    def process_question_with_token(self, user_input: str) -> Dict[str, Any]:
        """
        Main method for frontend integration - processes question with static token
        Returns structured response for API consumption
        """
        if not self.initialized:
            return {
                "success": False,
                "error": "Assistant not initialized",
                "response": "‚ùå Assistant not initialized. Please restart."
            }
        
        # Extract token and query
        token, actual_query = extract_token_and_query(user_input)
        
        # Determine category from token or fallback detection
        if token and token in [key.replace("_QUERY", "").replace("_", "") + "_QUERY" for key in STATIC_TOKENS.keys()]:
            # Normalize token format
            normalized_tokens = {
                "TEAM": "TEAM_QUERY",
                "GENERAL": "GENERAL_QUERY"
            }
            if token in normalized_tokens:
                token = normalized_tokens[token]
            elif not token.endswith("_QUERY"):
                token = token + "_QUERY"
                
            category = get_category_from_token(token)
        else:
            # Fallback to automatic detection
            category = detect_query_type_fallback(actual_query)
            token = "AUTO_DETECTED"
        
        try:
            # Process based on category
            if category == "team":
                response = self.query_database(actual_query, category)
            else:
                response = self.general_ai_response(actual_query)
            
            return {
                "success": True,
                "token_used": token,
                "category": category,
                "original_query": actual_query,
                "response": response,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Processing error: {e}")
            return {
                "success": False,
                "error": str(e),
                "response": f"‚ùå Error processing your request: {e}"
            }

    def process_question(self, question: str) -> str:
        """
        Backward compatibility method
        """
        result = self.process_question_with_token(question)
        return result["response"]

    def show_tokens(self):
        """
        Display available tokens for reference
        """
        print("üè∑Ô∏è  AVAILABLE STATIC TOKENS:")
        print("=" * 50)
        for token, info in STATIC_TOKENS.items():
            print(f"Token: {token}")
            print(f"Category: {info['category']}")
            print(f"Description: {info['description']}")
            print(f"Examples: {', '.join(info['examples'])}")
            print("-" * 30)

    def show_help(self):
        help_text = """
üìñ TEAM AI ASSISTANT HELP (Frontend Ready)

üè∑Ô∏è  STATIC TOKENS (for Frontend Integration):
  Usage: "TOKEN: your question"
  
  Available Tokens:
  - TEAM_QUERY: For team/user information
  - GENERAL_QUERY: For general AI assistance

üíæ DATABASE QUERIES:
  Team Info (use TEAM_QUERY token):
  - "TEAM_QUERY: Show all employees"
  - "TEAM_QUERY: Find user John Smith"
  - "TEAM_QUERY: List all team members"
  - "TEAM_QUERY: Count total employees"

ü§ñ GENERAL AI (use GENERAL_QUERY token):
  - "GENERAL_QUERY: Explain how databases work"
  - "GENERAL_QUERY: Help with team management"
  - "GENERAL_QUERY: What is SQL?"

üí° COMMANDS:
  - 'help' - Show this help
  - 'tokens' - Show available tokens
  - 'clear' - Clear screen
  - 'status' - Show system status
  - 'exit' - Quit assistant

üì° API Integration:
  Use process_question_with_token() method for structured responses
        """
        print(help_text)

    def show_status(self):
        print("üîç SYSTEM STATUS")
        print(f"üìÖ Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ü§ñ AI Model: Initialized ({'‚úÖ' if self.initialized else '‚ùå'})")
        print(f"üíæ Database Connections: {len(self.db_handlers)}")
        for category, handler in self.db_handlers.items():
            status = "‚úÖ" if handler['connection'].open else "‚ùå"
            print(f"   - {handler['config']['name']}: {status}")
        print(f"üè∑Ô∏è  Available Tokens: {len(STATIC_TOKENS)}")

    def start_interactive_session(self):
        if not self.initialize():
            return
        clear_screen()
        print("ü§ñ Team AI Assistant Ready (Frontend Integration Enabled)")
        print("Ask me about team members and employee information...")
        print("Type 'exit' to quit, 'tokens' to see available tokens\n")
        
        while True:
            try:
                question = input("üí¨ ").strip()
                if not question:
                    continue
                
                question_lower = question.lower()
                if question_lower in ['exit', 'quit', 'q']:
                    print("üëã Goodbye!")
                    break
                elif question_lower == 'help':
                    self.show_help()
                    continue
                elif question_lower == 'tokens':
                    self.show_tokens()
                    continue
                elif question_lower == 'clear':
                    clear_screen()
                    continue
                elif question_lower == 'status':
                    self.show_status()
                    continue
                
                result = self.process_question_with_token(question)
                print(f"\nüè∑Ô∏è  Token Used: {result.get('token_used', 'N/A')}")
                print(f"üìÇ Category: {result.get('category', 'N/A')}")
                print(f"üìù Response: {result['response']}\n")
                
                if result['success']:
                    feedback = input("Was this answer helpful? (yes/no/correction): ")
                    if feedback.lower() not in ['yes', 'y']:
                        self.save_feedback(result.get('original_query', question), result['response'], feedback)
                        
            except KeyboardInterrupt:
                print("\nüëã Goodbye!")
                break
            except Exception as e:
                print(f"\n‚ùå Error: {e}")
                logger.error(f"Session error: {e}", exc_info=True)
        
        # Close database connections
        for handler in self.db_handlers.values():
            if handler['connection'].open:
                handler['connection'].close()
        print("Connections closed.")

def main():
    assistant = TeamAIAssistant()
    
    # Example usage for frontend integration
    print("=== Frontend Integration Examples ===")
    assistant.initialize()
    
    # Example 1: With static token
    example1 = "TEAM_QUERY: Show me all employees"
    result1 = assistant.process_question_with_token(example1)
    print(f"Input: {example1}")
    print(f"Result: {result1}")
    print()
    
    # Example 2: Without token (auto-detection)
    example2 = "Who are the team members?"
    result2 = assistant.process_question_with_token(example2)
    print(f"Input: {example2}")
    print(f"Result: {result2}")
    print()
    
    # Start interactive session
    assistant.start_interactive_session()

if __name__ == "__main__":
    main()
