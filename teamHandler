import os
import re
import logging
import pymysql
import traceback
import time
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
import json
import sqlparse

# Import langchain components (required)
from langchain_community.utilities import SQLDatabase
from langchain_ollama import OllamaLLM
from langchain.chains import create_sql_query_chain

# --- TEAM DETAILS CONFIGURATION ---
TEAM_DB_CONFIG = {
    "name": "Team Details",
    "db_config": {
        "host": "localhost",
        "user": "root",
        "password": "root123",
        "database": "EIS_n"
    },
    "include_tables": ["UserMaster"],
}

# Blocked patterns for security
BLOCKED_PATTERNS = [
    r"\brm\b", r"\bkill\b", r"\breboot\b", r"\bshutdown\b", r"\buserdel\b",
    r"\bpasswd\b", r"\bmkfs\b", r"\bwget\b", r"\bcurl\b", r":\s*(){:|:&};:",
    r"\bsudo\b", r"\bsu\b", r"\bchmod\b", r"\bchown\b", r"\bdd\b",
    r"\bmount\s+/", r"\bumount\b", r"\bfdisk\b", r"\bparted\b", r"\bmkfs\b",
    r"\biptables\b", r"\bufw\b", r"\bfirewall\b", r"\bselinux\b"
]

# Sensitive field patterns (case-insensitive)
SENSITIVE_PATTERNS = [
    r"pwd", r"password", r"pass", r"secq", r"seca", r"secret", 
    r"auth", r"token", r"key", r"hash", r"salt"
]

# Setup logging
log_dir = os.path.expanduser("~")
log_file = os.path.join(log_dir, ".team_details_ai.log")

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def is_dangerous(text: str) -> bool:
    """Check if text contains dangerous patterns"""
    if not text:
        return False
    return any(re.search(pattern, text.lower()) for pattern in BLOCKED_PATTERNS)

def is_sensitive_field(field_name: str) -> bool:
    """Check if field name contains sensitive information"""
    if not field_name:
        return False
    return any(re.search(pattern, field_name.lower()) for pattern in SENSITIVE_PATTERNS)

class ContextManager:
    """Manages conversation context and provides relevant information"""
    
    def __init__(self, context: Dict = None):
        self.context = context or {}
        self.conversation_history = self.context.get('conversation_history', [])
        self.last_query_type = self.context.get('last_query_type')
        self.last_results = self.context.get('last_results')
    
    def get_relevant_context(self, current_query: str) -> str:
        """Extract relevant context for the current query"""
        if not self.conversation_history:
            return ""
        
        context_info = []
        
        # Look for pronoun references and context clues
        current_lower = current_query.lower()
        
        # Check for pronouns that might reference previous queries
        pronouns = ['he', 'she', 'they', 'him', 'her', 'them', 'his', 'their', 'this', 'that', 'these', 'those']
        has_pronouns = any(pronoun in current_lower.split() for pronoun in pronouns)
        
        # Check for continuation words
        continuation_words = ['also', 'and', 'more', 'other', 'another', 'same', 'similar']
        has_continuation = any(word in current_lower for word in continuation_words)
        
        # Check for incomplete references
        incomplete_refs = ['phone', 'email', 'contact', 'details', 'info', 'information']
        has_incomplete_ref = any(ref in current_lower for ref in incomplete_refs) and len(current_query.split()) <= 3
        
        if has_pronouns or has_continuation or has_incomplete_ref:
            # Get the last few relevant interactions
            recent_context = self.conversation_history[-3:]  # Last 3 interactions
            
            for interaction in recent_context:
                if interaction.get('query_type') == 'team':
                    context_info.append(f"Previous query: {interaction['query']}")
                    
                    # Extract names or IDs from previous responses
                    response = interaction.get('response', '')
                    if response:
                        # Look for employee names or IDs in previous responses
                        name_matches = re.findall(r'Name[:\s]+([A-Za-z\s]+)', response, re.IGNORECASE)
                        id_matches = re.findall(r'(?:ID|Employee ID)[:\s]+(\w+)', response, re.IGNORECASE)
                        
                        if name_matches:
                            context_info.append(f"Previously mentioned employee: {name_matches[0].strip()}")
                        if id_matches:
                            context_info.append(f"Previously mentioned ID: {id_matches[0].strip()}")
        
        return " | ".join(context_info) if context_info else ""
    
    def enhance_query_with_context(self, query: str) -> str:
        """Enhance the current query with relevant context"""
        context_str = self.get_relevant_context(query)
        
        if context_str:
            enhanced_query = f"Context: {context_str} | Current Query: {query}"
            logger.info(f"Enhanced query with context: {enhanced_query}")
            return enhanced_query
        
        return query
    
    def detect_follow_up_type(self, query: str) -> str:
        """Detect if this is a follow-up query and what type"""
        if not self.conversation_history:
            return "initial"
        
        query_lower = query.lower()
        
        # Check for specific follow-up patterns
        if any(word in query_lower for word in ['phone', 'contact', 'number']):
            return "contact_info"
        elif any(word in query_lower for word in ['email', 'mail']):
            return "email_info"
        elif any(word in query_lower for word in ['team', 'department', 'group']):
            return "team_info"
        elif any(word in query_lower for word in ['position', 'role', 'designation']):
            return "role_info"
        elif any(word in query_lower for word in ['more', 'details', 'info', 'information']):
            return "detailed_info"
        elif any(word in query_lower for word in ['he', 'she', 'him', 'her', 'they', 'them']):
            return "pronoun_reference"
        
        return "general"

class DatabaseSchemaManager:
    """Manages database schema discovery and caching"""
    
    def __init__(self, connection):
        self.connection = connection
        self.schema_cache = {}
        self.field_mappings = {}
        self.safe_columns = []
        self.load_schema()
    
    def load_schema(self):
        """Load and cache database schema with enhanced debugging"""
        try:
            print("DEBUG - Loading database schema...")
            
            with self.connection.cursor() as cursor:
                # First, check if UserMaster table exists
                cursor.execute("""
                    SELECT TABLE_NAME 
                    FROM INFORMATION_SCHEMA.TABLES 
                    WHERE TABLE_SCHEMA = %s AND TABLE_NAME = 'UserMaster'
                """, (TEAM_DB_CONFIG['db_config']['database'],))
                
                table_check = cursor.fetchone()
                if not table_check:
                    # Try to find similar tables
                    cursor.execute("""
                        SELECT TABLE_NAME 
                        FROM INFORMATION_SCHEMA.TABLES 
                        WHERE TABLE_SCHEMA = %s AND TABLE_NAME LIKE '%user%'
                    """, (TEAM_DB_CONFIG['db_config']['database'],))
                    similar_tables = cursor.fetchall()
                    
                    error_msg = "UserMaster table not found in database."
                    if similar_tables:
                        table_names = [t['TABLE_NAME'] for t in similar_tables]
                        error_msg += f" Similar tables found: {', '.join(table_names)}"
                    
                    print(f"DEBUG - {error_msg}")
                    raise Exception(error_msg)
                
                print("DEBUG - UserMaster table found, loading columns...")
                
                # Get all columns for UserMaster table
                cursor.execute("""
                    SELECT COLUMN_NAME, DATA_TYPE, IS_NULLABLE, COLUMN_DEFAULT, COLUMN_COMMENT
                    FROM INFORMATION_SCHEMA.COLUMNS 
                    WHERE TABLE_SCHEMA = %s AND TABLE_NAME = 'UserMaster'
                    ORDER BY ORDINAL_POSITION
                """, (TEAM_DB_CONFIG['db_config']['database'],))
                
                columns = cursor.fetchall()
                print(f"DEBUG - Found {len(columns)} columns in UserMaster table")
                
                if not columns:
                    raise Exception("UserMaster table exists but no columns are accessible")
                
                self.schema_cache['UserMaster'] = {}
                self.safe_columns = []
                
                print("DEBUG - Processing columns:")
                for col in columns:
                    col_name = col['COLUMN_NAME']
                    col_type = col['DATA_TYPE']
                    
                    print(f"DEBUG -   Column: {col_name} ({col_type})")
                    
                    # Skip sensitive fields
                    if is_sensitive_field(col_name):
                        print(f"DEBUG -     -> Skipped (sensitive)")
                        logger.info(f"Skipping sensitive field: {col_name}")
                        continue
                    
                    print(f"DEBUG -     -> Added to safe columns")
                    self.safe_columns.append(col_name)
                    self.schema_cache['UserMaster'][col_name] = {
                        'type': col_type,
                        'nullable': col['IS_NULLABLE'] == 'YES',
                        'default': col['COLUMN_DEFAULT'],
                        'comment': col['COLUMN_COMMENT'] or ''
                    }
                
                print(f"DEBUG - Schema loaded with {len(self.safe_columns)} safe columns: {self.safe_columns}")
                logger.info(f"Loaded schema with {len(self.safe_columns)} safe columns: {self.safe_columns}")
                
                # Create intelligent field mappings based on actual columns
                self._create_field_mappings()
                print("DEBUG - Field mappings created")
                
        except Exception as e:
            logger.error(f"Schema loading failed: {e}")
            print(f"DEBUG - Schema loading failed: {e}")
            
            # Set minimal fallback columns if schema loading fails
            self.safe_columns = []
            print("DEBUG - Using fallback: trying to get columns from table directly")
            
            try:
                with self.connection.cursor() as cursor:
                    cursor.execute("DESCRIBE UserMaster")
                    desc_result = cursor.fetchall()
                    for row in desc_result:
                        col_name = row['Field']
                        if not is_sensitive_field(col_name):
                            self.safe_columns.append(col_name)
                    print(f"DEBUG - Fallback found columns: {self.safe_columns}")
            except Exception as fallback_error:
                print(f"DEBUG - Fallback also failed: {fallback_error}")
                self.safe_columns = ['*']  # Last resort
            
            if not self.safe_columns:
                raise Exception(f"Could not load any safe columns from database: {e}")
    
    def _create_field_mappings(self):
        """Create intelligent field mappings based on actual column names"""
        self.field_mappings = {}
        
        # Find actual columns for common terms
        id_col = self._find_column_by_patterns(['uid', 'user_?id', 'emp_?id', 'employee_?id', '^id$'])
        name_col = self._find_column_by_patterns(['name', 'emp_?name', 'employee_?name', 'full_?name'])
        contact_col = self._find_column_by_patterns(['contact', 'phone', 'mobile', 'cell'])
        email_col = self._find_column_by_patterns(['email', 'mail', 'e_?mail'])
        position_col = self._find_column_by_patterns(['position', 'role', 'designation', 'title'])
        team_col = self._find_column_by_patterns(['team', 'group', 'department', 'dept'])
        project_col = self._find_column_by_patterns(['project', 'proj'])
        level_col = self._find_column_by_patterns(['level', 'grade', 'band'])
        
        # Create mappings
        if id_col:
            self.field_mappings['id'] = id_col
            self.field_mappings['employee_id'] = id_col
            self.field_mappings['emp_id'] = id_col
            self.field_mappings['user_id'] = id_col
        
        if name_col:
            self.field_mappings['name'] = name_col
            self.field_mappings['employee_name'] = name_col
            self.field_mappings['emp_name'] = name_col
        
        if contact_col:
            self.field_mappings['phone'] = contact_col
            self.field_mappings['mobile'] = contact_col
            self.field_mappings['contact'] = contact_col
            self.field_mappings['phone_number'] = contact_col
        
        if email_col:
            self.field_mappings['email'] = email_col
            self.field_mappings['mail'] = email_col
        
        if position_col:
            self.field_mappings['position'] = position_col
            self.field_mappings['role'] = position_col
            self.field_mappings['designation'] = position_col
        
        if team_col:
            self.field_mappings['team'] = team_col
            self.field_mappings['department'] = team_col
            self.field_mappings['group'] = team_col
        
        if project_col:
            self.field_mappings['project'] = project_col
        
        if level_col:
            self.field_mappings['level'] = level_col
            self.field_mappings['grade'] = level_col
    
    def _find_column_by_patterns(self, patterns: List[str]) -> Optional[str]:
        """Find column by matching patterns"""
        for pattern in patterns:
            for col in self.safe_columns:
                if re.search(pattern, col.lower()):
                    return col
        return None
    
    def get_safe_columns(self) -> List[str]:
        """Get list of safe (non-sensitive) columns"""
        return self.safe_columns.copy()
    
    def map_user_terms(self, question: str) -> str:
        """Map user terms to actual database columns"""
        mapped_question = question.lower()
        
        for term, actual_column in self.field_mappings.items():
            pattern = rf'\b{re.escape(term)}\b'
            mapped_question = re.sub(pattern, actual_column, mapped_question, flags=re.IGNORECASE)
        
        return mapped_question
    
    def get_column_info_string(self) -> str:
        """Get formatted column information for LLM context"""
        if 'UserMaster' not in self.schema_cache:
            return f"Available columns: {', '.join(self.safe_columns)}"
        
        info_parts = []
        for col_name, col_info in self.schema_cache['UserMaster'].items():
            type_info = col_info['type']
            if type_info in ['varchar', 'text', 'char']:
                usage = "text - use LIKE '%value%' for partial matching"
            elif type_info in ['int', 'bigint', 'decimal']:
                usage = "numeric - use = for exact matching"
            elif type_info in ['datetime', 'date', 'timestamp']:
                usage = "date - use appropriate date functions"
            else:
                usage = f"{type_info} - handle appropriately"
            
            info_parts.append(f"{col_name}: {usage}")
        
        return "\n".join(info_parts)

class SQLQueryProcessor:
    """Processes and validates SQL queries with context awareness"""
    
    def __init__(self, schema_manager: DatabaseSchemaManager, context_manager: ContextManager = None):
        self.schema_manager = schema_manager
        self.context_manager = context_manager
    
    def clean_and_validate_sql(self, raw_sql: str, question: str) -> Tuple[str, bool]:
        """Clean SQL and validate it's safe with context consideration"""
        try:
            logger.info(f"Processing raw SQL: {raw_sql}")
            
            # Handle non-SQL responses
            if not self._contains_sql(raw_sql):
                return "", False
            
            # Extract SQL from various formats
            sql = self._extract_sql(raw_sql)
            
            if not sql:
                return "", False
            
            # Validate and clean
            if not self._is_safe_select(sql):
                return "", False
            
            # Remove sensitive fields
            sql = self._remove_sensitive_fields(sql)
            
            # Fix column references
            sql = self._fix_column_references(sql)
            
            # Apply context-based optimizations
            if self.context_manager:
                sql = self._apply_context_optimizations(sql, question)
            
            # Optimize for text searches
            sql = self._optimize_text_searches(sql)
            
            # Add limits and final cleanup
            sql = self._finalize_sql(sql)
            
            logger.info(f"Final processed SQL: {sql}")
            return sql, True
            
        except Exception as e:
            logger.error(f"SQL processing error: {e}")
            return "", False
    
    def _apply_context_optimizations(self, sql: str, question: str) -> str:
        """Apply context-based optimizations to SQL"""
        if not self.context_manager or not self.context_manager.conversation_history:
            return sql
        
        # Get the follow-up type
        follow_up_type = self.context_manager.detect_follow_up_type(question)
        
        if follow_up_type == "pronoun_reference":
            # Try to extract name or ID from previous context
            context_str = self.context_manager.get_relevant_context(question)
            
            # Look for employee names or IDs in context
            name_match = re.search(r'Previously mentioned employee:\s*([A-Za-z\s]+)', context_str)
            id_match = re.search(r'Previously mentioned ID:\s*(\w+)', context_str)
            
            if name_match and not re.search(r'WHERE.*LIKE.*%.*%', sql, re.IGNORECASE):
                name = name_match.group(1).strip()
                # Add WHERE clause for the name if not already present
                if 'WHERE' not in sql.upper():
                    name_col = self.schema_manager.field_mappings.get('name', 'name')
                    sql += f" WHERE `{name_col}` LIKE '%{name}%'"
            elif id_match and not re.search(r'WHERE.*=', sql, re.IGNORECASE):
                emp_id = id_match.group(1).strip()
                # Add WHERE clause for the ID if not already present
                if 'WHERE' not in sql.upper():
                    id_col = self.schema_manager.field_mappings.get('id', 'id')
                    sql += f" WHERE `{id_col}` = '{emp_id}'"
        
        return sql
    
    def _contains_sql(self, text: str) -> bool:
        """Check if text contains SQL"""
        if not text:
            return False
        sql_indicators = ['select', 'from', 'where', 'join']
        text_lower = text.lower()
        return any(indicator in text_lower for indicator in sql_indicators)
    
    def _extract_sql(self, raw_sql: str) -> str:
        """Extract SQL from various formats"""
        if not raw_sql:
            return ""
            
        # Try code block first
        code_block_match = re.search(r"```sql\s*(.*?)\s*```", raw_sql, re.DOTALL | re.IGNORECASE)
        if code_block_match:
            return code_block_match.group(1).strip()
        
        # Try to find SELECT statement
        select_match = re.search(r"(SELECT.*?)(?:\n\n|$|;)", raw_sql, re.IGNORECASE | re.DOTALL)
        if select_match:
            return select_match.group(1).strip()
        
        # Clean and return
        sql = re.sub(r"```", "", raw_sql)
        sql = re.sub(r"^.*?(SELECT|INSERT|UPDATE|DELETE)", r"\1", sql, flags=re.IGNORECASE | re.DOTALL)
        return sql.strip()
    
    def _is_safe_select(self, sql: str) -> bool:
        """Validate SQL is safe SELECT only"""
        if not sql:
            return False
            
        sql_clean = sql.strip().lower()
        
        if not sql_clean.startswith('select'):
            return False
        
        dangerous_keywords = [
            'insert', 'update', 'delete', 'drop', 'alter', 'create', 
            'truncate', 'exec', 'execute', 'sp_', 'xp_'
        ]
        
        return not any(keyword in sql_clean for keyword in dangerous_keywords)
    
    def _remove_sensitive_fields(self, sql: str) -> str:
        """Remove references to sensitive fields"""
        safe_columns = self.schema_manager.get_safe_columns()
        
        if not safe_columns:
            return sql
        
        # If SELECT *, replace with safe columns
        if re.search(r'SELECT\s+\*', sql, re.IGNORECASE):
            safe_cols_str = ', '.join(f"`{col}`" for col in safe_columns if col != '*')
            if safe_cols_str:
                sql = re.sub(r'SELECT\s+\*', f'SELECT {safe_cols_str}', sql, flags=re.IGNORECASE)
        
        return sql
    
    def _fix_column_references(self, sql: str) -> str:
        """Fix column references to match actual schema"""
        safe_columns = self.schema_manager.get_safe_columns()
        
        # First, normalize all existing backticks and quotes
        # Remove any existing backticks/quotes around column names
        for actual_col in safe_columns:
            if actual_col == '*':
                continue
            
            # Remove various quote patterns and replace with single backticks
            patterns_to_clean = [
                (f'```{actual_col}```', f'`{actual_col}`'),  # Triple backticks
                (f'``{actual_col}``', f'`{actual_col}`'),    # Double backticks
                (f'"{actual_col}"', f'`{actual_col}`'),       # Double quotes
                (f"'{actual_col}'", f'`{actual_col}`'),       # Single quotes
            ]
            
            for pattern, replacement in patterns_to_clean:
                sql = sql.replace(pattern, replacement)
            
            # Handle unquoted column names (but be careful with SQL keywords)
            # Use word boundaries to avoid partial matches
            import re
            sql = re.sub(f'\\b{re.escape(actual_col)}\\b(?![`"\'])', f'`{actual_col}`', sql, flags=re.IGNORECASE)
        
        # Clean up any remaining double backticks that might have been created
        sql = re.sub(r'`{2,}', '`', sql)
        
        return sql
    
    def _optimize_text_searches(self, sql: str) -> str:
        """Optimize text field searches"""
        if 'UserMaster' not in self.schema_manager.schema_cache:
            return sql
            
        for col_name, col_info in self.schema_manager.schema_cache['UserMaster'].items():
            if col_info.get('type') in ['varchar', 'text', 'char']:
                # Convert = to LIKE for text fields - handle various quote patterns
                patterns = [
                    (f"`{col_name}`\\s*=\\s*'([^']*)'", f"`{col_name}` LIKE '%\\1%'"),
                    (f"`{col_name}`\\s*=\\s*\"([^\"]*)\"", f"`{col_name}` LIKE '%\\1%'"),
                ]
                
                for pattern, replacement in patterns:
                    sql = re.sub(pattern, replacement, sql, flags=re.IGNORECASE)
        
        return sql
    
    def _finalize_sql(self, sql: str) -> str:
        """Final SQL cleanup and optimization"""
        if not sql:
            return sql
            
        # Remove trailing semicolons
        sql = sql.strip().rstrip(';')
        
        # Add reasonable limit if none exists
        if not re.search(r'\bLIMIT\b', sql, re.IGNORECASE):
            if not re.search(r'\bCOUNT\s*\(', sql, re.IGNORECASE):
                sql += " LIMIT 50"  # Increased default limit
        
        # Ensure minimum limit of 20
        elif re.search(r'\bLIMIT\s+(\d+)\b', sql, re.IGNORECASE):
            def increase_limit(match):
                current_limit = int(match.group(1))
                return f"LIMIT {max(current_limit, 20)}"
            sql = re.sub(r'\bLIMIT\s+(\d+)\b', increase_limit, sql, flags=re.IGNORECASE)
        
        # Clean up extra whitespace
        sql = re.sub(r'\s+', ' ', sql).strip()
        
        return sql

class ResultFormatter:
    """Formats query results for display with context awareness"""
    
    def __init__(self, context_manager: ContextManager = None):
        self.context_manager = context_manager
    
    def format_natural(self, result: List[Dict], question: str) -> str:
        """Format results in natural language with context consideration"""
        if not result:
            return self._no_results_message(question)
        
        # Check if this is a follow-up query
        follow_up_type = "initial"
        if self.context_manager:
            follow_up_type = self.context_manager.detect_follow_up_type(question)
        
        # Handle single value results
        if len(result) == 1 and len(result[0]) == 1:
            value = list(result[0].values())[0]
            if "count" in question.lower():
                return f"There are {value} employee records matching your criteria."
            return f"The result is: {value}"
        
        # Handle single record
        if len(result) == 1:
            return self._format_single_record(result[0], follow_up_type)
        
        # Handle multiple records
        return self._format_multiple_records(result, question, follow_up_type)
    
    def _no_results_message(self, question: str) -> str:
        """Generate helpful no results message with context awareness"""
        base_suggestions = [
            "Try using broader search terms",
            "Check spelling of names or terms",
            "Try searching by partial matches",
            "Verify the data exists in the database"
        ]
        
        # Add context-specific suggestions
        if self.context_manager and self.context_manager.conversation_history:
            context_suggestions = [
                "Make sure you're referring to the same employee from previous queries",
                "Try using the full name or employee ID from earlier results"
            ]
            base_suggestions.extend(context_suggestions)
        
        response = "I couldn't find any employee records matching your criteria.\n\n"
        response += "üí° Suggestions:\n"
        response += "\n".join(f"‚Ä¢ {suggestion}" for suggestion in base_suggestions)
        
        return response
    
    def _format_single_record(self, record: Dict, follow_up_type: str = "initial") -> str:
        """Format single record nicely with context awareness"""
        if follow_up_type == "contact_info":
            # Focus on contact information
            contact_info = []
            for key, value in record.items():
                if any(term in key.lower() for term in ['contact', 'phone', 'mobile', 'cell']):
                    contact_info.append(f"üìû {key}: {value}")
            if contact_info:
                return "üìû Contact Information:\n" + "\n".join(contact_info)
        
        elif follow_up_type == "email_info":
            # Focus on email information
            email_info = []
            for key, value in record.items():
                if any(term in key.lower() for term in ['email', 'mail']):
                    email_info.append(f"üìß {key}: {value}")
            if email_info:
                return "üìß Email Information:\n" + "\n".join(email_info)
        
        elif follow_up_type == "team_info":
            # Focus on team/department information
            team_info = []
            for key, value in record.items():
                if any(term in key.lower() for term in ['team', 'department', 'group', 'project']):
                    team_info.append(f"üë• {key}: {value}")
            if team_info:
                return "üë• Team Information:\n" + "\n".join(team_info)
        
        # Default comprehensive format
        response = "I found 1 employee record:\n\n"
        
        # Define display order and icons with flexible field matching
        field_patterns = [
            ('üÜî Employee ID', ['uid', 'id', 'emp_id', 'employee_id', 'user_id']),
            ('üë§ Name', ['empname', 'name', 'employee_name', 'full_name', 'emp_name']),
            ('üìû Contact', ['contact', 'phone', 'mobile', 'cell', 'telephone']),
            ('üìß Email', ['email', 'mail', 'tcsemail', 'sbiemail', 'e_mail']),
            ('üîë AD ID', ['adid', 'ad_id', 'active_directory_id']),
            ('üíº Position', ['position', 'role', 'designation', 'title', 'job']),
            ('üìä Level', ['level', 'grade', 'band']),
            ('üë• Team', ['team', 'department', 'group', 'dept']),
            ('üìÇ Project', ['project', 'proj'])
        ]
        
        displayed_fields = set()
        
        for icon_label, possible_fields in field_patterns:
            for field in possible_fields:
                # Find matching field (case-insensitive)
                actual_field = None
                for record_key in record.keys():
                    if record_key.lower() == field.lower():
                        actual_field = record_key
                        break
                
                if actual_field and record[actual_field] is not None and str(record[actual_field]).strip():
                    response += f"{icon_label}: {record[actual_field]}\n"
                    displayed_fields.add(actual_field)
                    break
        
        # Add any remaining fields not in the standard display
        for key, value in record.items():
            if key not in displayed_fields and value is not None and str(value).strip():
                response += f"üìã {key}: {value}\n"
        
        # Add context-aware follow-up suggestions
        if self.context_manager:
            response += "\nüí¨ You can ask for specific details like 'phone number', 'email', or 'team info'"
        
        return response.strip()
    
    def _format_multiple_records(self, result: List[Dict], question: str, follow_up_type: str = "initial") -> str:
        """Format multiple records with summary and context awareness"""
        response = f"I found {len(result)} employee records matching your criteria:\n\n"
        
        # Add summary if we have team information
        team_field = None
        for field in ['Team', 'team', 'Department', 'department', 'Group', 'group']:
            if field in result[0]:
                team_field = field
                break
        
        if team_field:
            team_counts = {}
            for record in result:
                team = record.get(team_field, 'Unknown')
                if team:
                    team_counts[team] = team_counts.get(team, 0) + 1
            
            if len(team_counts) > 1:
                response += "üìä Team Summary:\n"
                for team, count in sorted(team_counts.items()):
                    response += f"   ‚Ä¢ {team}: {count} employees\n"
                response += "\n"
        
        # Show detailed results
        response += "üìã Detailed Results:\n"
        response += self._format_tabular(result)
        
        # Add context-aware suggestions for multiple results
        if self.context_manager and len(result) > 5:
            response += "\n\nüí° Tip: You can ask for specific details about any employee by name or ID"
        
        return response
    
    def _format_tabular(self, result: List[Dict]) -> str:
        """Format results in table format optimized for frontend display"""
        if not result:
            return "No records found."
        
        columns = list(result[0].keys())
        
        # Calculate column widths with max of 30 characters
        col_widths = []
        for col in columns:
            max_width = max(
                len(str(col)),
                max(len(str(row.get(col, ''))) for row in result) if result else 0
            )
            col_widths.append(min(max_width, 30))  # Cap at 30 chars
        
        # Build table with better formatting
        output = []
        
        # Header with separator
        header = "| " + " | ".join(
            str(col).center(width) for col, width in zip(columns, col_widths)
        ) + " |"
        separator = "+-" + "-+-".join(
            "-" * width for width in col_widths
        ) + "-+"
        
        output.append(separator)
        output.append(header)
        output.append(separator)
        
        # Rows with proper alignment
        for row in result:
            formatted_cells = []
            for col, width in zip(columns, col_widths):
                cell_value = str(row.get(col, ''))
                if len(cell_value) > 30:
                    cell_value = cell_value[:27] + "..."
                formatted_cells.append(cell_value.ljust(width))
            
            formatted_row = "| " + " | ".join(formatted_cells) + " |"
            output.append(formatted_row)
        
        output.append(separator)
        output.append(f"Total records: {len(result)}")
        
        return "\n".join(output)

class TeamDetailsAssistant:
    def __init__(self, context: Dict = None):
        self.llm = None
        self.db_connection = None
        self.schema_manager = None
        self.sql_processor = None
        self.context_manager = ContextManager(context)
        self.result_formatter = ResultFormatter(self.context_manager)
        self.initialized = False
    
    def initialize(self) -> bool:
        """Initialize the assistant with robust error handling"""
        try:
            logger.info("Initializing Team Details Assistant...")
            
            # Initialize database connection first
            if not self._init_database():
                return False
            
            # Initialize LLM (required)
            if not self._init_llm():
                raise ImportError("LangChain components could not be initialized")
            
            # Initialize schema manager
            self.schema_manager = DatabaseSchemaManager(self.db_connection)
            self.sql_processor = SQLQueryProcessor(self.schema_manager, self.context_manager)
            
            self.initialized = True
            logger.info("Team Details Assistant initialized successfully")
            return True
            
        except Exception as e:
            logger.error(f"Initialization failed: {e}\n{traceback.format_exc()}")
            return False
    
    def _init_database(self) -> bool:
        """Initialize database connection with enhanced debugging"""
        try:
            db_cfg = TEAM_DB_CONFIG['db_config']
            print(f"DEBUG - Connecting to database: {db_cfg['host']}/{db_cfg['database']}")
            
            self.db_connection = pymysql.connect(
                host=db_cfg['host'],
                user=db_cfg['user'],
                password=db_cfg['password'],
                database=db_cfg['database'],
                charset='utf8mb4',
                cursorclass=pymysql.cursors.DictCursor,
                autocommit=True,
                connect_timeout=10,
                read_timeout=30
            )
            
            # Test connection
            with self.db_connection.cursor() as cursor:
                cursor.execute("SELECT 1 as test")
                test_result = cursor.fetchone()
                print(f"DEBUG - Database connection test: {test_result}")
            
            print("DEBUG - Database connection established successfully")
            logger.info("Database connection established")
            return True
            
        except Exception as e:
            error_msg = f"Database connection failed: {e}"
            logger.error(error_msg)
            print(f"DEBUG - {error_msg}")
            
            # Additional debugging info
            db_cfg = TEAM_DB_CONFIG['db_config']
            print(f"DEBUG - Connection details:")
            print(f"DEBUG -   Host: {db_cfg['host']}")
            print(f"DEBUG -   User: {db_cfg['user']}")
            print(f"DEBUG -   Database: {db_cfg['database']}")
            
            return False
    
    def _init_llm(self) -> bool:
        """Initialize LLM (required)"""
        try:
            self.llm = OllamaLLM(model="myllm:latest", temperature=0.1)
            # Test LLM
            test_response = self.llm.invoke("SELECT 1")
            logger.info("LLM initialized successfully")
            return True
        except Exception as e:
            logger.error(f"LLM initialization failed: {e}")
            return False
    
    def process_question(self, question: str) -> str:
        """Process user question and return results with enhanced debugging and context"""
        if not self.initialized and not self.initialize():
            return "‚ùå Team Details Assistant initialization failed. Please check database connection and LLM setup."
        
        if is_dangerous(question):
            return "‚ùå Question blocked for security reasons."
        
        try:
            print(f"DEBUG - Processing question: {question}")
            
            # Enhance query with context
            enhanced_question = self.context_manager.enhance_query_with_context(question)
            print(f"DEBUG - Enhanced question: {enhanced_question}")
            
            # Map user terms to database columns
            mapped_question = self.schema_manager.map_user_terms(enhanced_question)
            print(f"DEBUG - Mapped question: {mapped_question}")
            
            # Generate SQL using LLM
            print("DEBUG - Using LLM for SQL generation")
            raw_sql = self._generate_sql_with_llm(mapped_question)
            
            print(f"DEBUG - Raw SQL generated: {raw_sql}")
            
            # Process and validate SQL
            final_sql, is_valid = self.sql_processor.clean_and_validate_sql(raw_sql, question)
            print(f"DEBUG - Final SQL: {final_sql}")
            print(f"DEBUG - SQL is valid: {is_valid}")
            
            if not is_valid:
                return f"‚ùå Could not generate valid SQL query. Please rephrase your question.\nDebug info: {raw_sql}"
            
            # Execute query with performance optimization
            start_time = time.time()
            result = self._execute_query(final_sql)
            query_time = time.time() - start_time
            print(f"DEBUG - Query executed in {query_time:.2f} seconds")
            
            if result is None:
                return "‚ùå Query execution failed. Check the debug output above for details."
            
            print(f"DEBUG - Query execution successful, formatting results...")
            
            # Format and return results with context awareness
            formatted_result = self.result_formatter.format_natural(result, question)
            return formatted_result
            
        except Exception as e:
            error_trace = traceback.format_exc()
            logger.error(f"Question processing error: {e}\n{error_trace}")
            print(f"DEBUG - Question processing error: {e}")
            print(f"DEBUG - Full traceback: {error_trace}")
            return f"‚ùå Error processing your question: {str(e)}"
    
    def _generate_sql_with_llm(self, question: str) -> str:
        """Generate SQL using LLM with context awareness"""
        try:
            # Create context for LLM
            schema_info = self.schema_manager.get_column_info_string()
            safe_columns = self.schema_manager.get_safe_columns()
            
            # Add context information to the prompt
            context_info = ""
            if self.context_manager and self.context_manager.conversation_history:
                context_str = self.context_manager.get_relevant_context(question)
                if context_str:
                    context_info = f"\nContext from previous conversation: {context_str}\n"
            
            context = f"""
Question: {question}
{context_info}
Database: UserMaster table with the following columns:
{schema_info}

IMPORTANT RULES:
1. ONLY use SELECT statements
2. ONLY reference these available columns: {', '.join(safe_columns)}
3. Use LIKE '%value%' for text searches, not exact equals
4. For numeric IDs, use exact equals (=)
5. Always include proper table name: UserMaster
6. Do not include sensitive fields in any query
7. Limit results appropriately (minimum LIMIT 20)
8. If the question refers to previous context, use the context information provided

Generate a SQL query to answer the question.
"""
            
            # Create a simple query chain
            db_cfg = TEAM_DB_CONFIG['db_config']
            uri = f"mysql+pymysql://{db_cfg['user']}:{db_cfg['password']}@{db_cfg['host']}/{db_cfg['database']}"
            
            db_for_llm = SQLDatabase.from_uri(
                uri,
                include_tables=TEAM_DB_CONFIG.get("include_tables", ["UserMaster"])
            )
            
            chain = create_sql_query_chain(self.llm, db_for_llm)
            raw_sql = chain.invoke({"question": context})
            
            logger.info(f"Generated SQL with LLM: {raw_sql}")
            return raw_sql
                
        except Exception as e:
            logger.error(f"SQL generation with LLM failed: {e}")
            raise Exception("Failed to generate SQL query using LLM")
    
    def _execute_query(self, sql: str) -> Optional[List[Dict]]:
        """Execute SQL query with performance optimizations"""
        try:
            # Check if connection is still alive
            if not self.db_connection.open:
                logger.info("Database connection is closed, attempting to reconnect...")
                if not self._init_database():
                    return None
            
            with self.db_connection.cursor() as cursor:
                # Set faster fetch size
                cursor.arraysize = 100  # Fetch more rows at once
                
                # Execute with timeout
                start_time = time.time()
                cursor.execute(sql)
                
                # Stream results for large datasets
                result = []
                batch = cursor.fetchmany(100)  # Fetch in batches
                while batch:
                    result.extend(batch)
                    if len(result) >= 1000:  # Safety limit
                        break
                    batch = cursor.fetchmany(100)
                
                logger.info(f"Query executed in {time.time() - start_time:.2f}s, returned {len(result)} rows")
                return result
                
        except Exception as e:
            logger.error(f"Query execution error: {e}")
            return None
    
    def cleanup(self):
        """Clean up resources"""
        try:
            if self.db_connection and self.db_connection.open:
                self.db_connection.close()
                logger.info("Database connection closed")
        except Exception as e:
            logger.error(f"Cleanup error: {e}")

def Teammain(query: str, context: Dict = None) -> str:
    """Main function to process team queries with context support"""
    if not query or not query.strip():
        return "‚ùå Please provide a valid query."
    
    logger.info(f"Processing query: {query}")
    if context:
        logger.info(f"Context history length: {len(context.get('conversation_history', []))}")
    
    assistant = TeamDetailsAssistant(context)
    
    try:
        result = assistant.process_question(query.strip())
        return result
    except Exception as e:
        logger.error(f"Main function error: {e}")
        return f"‚ùå An unexpected error occurred: {str(e)}"
    finally:
        assistant.cleanup()

# Test the function
if __name__ == "__main__":
    # Test with sample queries and context
    test_context = {
        'conversation_history': [
            {
                'query': 'Show me employee with name Aryan',
                'response': 'üÜî Employee ID: 12345\nüë§ Name: Aryan Kumar\nüìû Contact: 9876543210',
                'timestamp': time.time() - 300,
                'query_type': 'team'
            }
        ],
        'last_query_type': 'team',
        'created_at': time.time() - 300
    }
    
    test_queries = [
        ("Show me employee with ID 12345", None),
        ("tell me details about aryan", None), 
        ("his phone number", test_context),  # Context-dependent query
        ("what is his email?", test_context),  # Context-dependent query
        ("List all employees in team ABC", None),
        ("Count employees by team", None)
    ]
    
    print("üöÄ Starting Team Details Assistant Tests with Context...")
    print("=" * 60)
    
    for i, (query, context) in enumerate(test_queries, 1):
        print(f"\nüîç Test {i}: {query}")
        if context:
            print(f"üìã Context: Previous query about {context['conversation_history'][-1]['query']}")
        print("-" * 40)
        try:
            result = Teammain(query, context)
            print(result)
        except Exception as e:
            print(f"‚ùå Error in test {i}: {e}")
        print("-" * 40)
    
    print("\n‚úÖ All tests completed!")
