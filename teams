import os
import re
import logging
import pymysql
import traceback
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime, timedelta
import json
import sqlparse
from langchain_community.utilities import SQLDatabase
from langchain_ollama import OllamaLLM
from langchain.chains import create_sql_query_chain
import hashlib
from collections import defaultdict

# --- TEAM DETAILS CONFIGURATION ---
TEAM_DB_CONFIG = {
    "name": "Team Details",
    "db_config": {
        "host": "localhost",
        "user": "root",
        "password": "root123",
        "database": "EIS_n"
    },
    "include_tables": ["UserMaster"],
}

# Enhanced field mappings based on actual table structure
FIELD_MAPPINGS = {
    # Employee ID variations
    "employee_id": "Uid",
    "emp_id": "Uid", 
    "id": "Uid",
    "employee id": "Uid",
    "user id": "Uid",
    "uid": "Uid",
    
    # Name variations
    "name": "EmpName",
    "employee_name": "EmpName",
    "emp_name": "EmpName",
    "employee name": "EmpName",
    "full name": "EmpName",
    
    # Contact variations
    "phone": "Contact",
    "mobile": "Contact", 
    "contact": "Contact",
    "phone_number": "Contact",
    "phone number": "Contact",
    "mobile number": "Contact",
    "cell phone": "Contact",
    "telephone": "Contact",
    
    # Email variations
    "email": "TcsEmail",
    "tcs_email": "TcsEmail",
    "tcs email": "TcsEmail",
    "company email": "TcsEmail",
    "work email": "TcsEmail",
    "sbi_email": "SbiEmail",
    "sbi email": "SbiEmail",
    "secondary email": "SbiEmail",
    
    # Team and project
    "team": "Team",
    "team name": "Team",
    "department": "Team",
    "group": "Team",
    "project": "Project",
    "project name": "Project",
    
    # Position and level
    "position": "Position",
    "role": "Position",
    "designation": "Position",
    "job title": "Position",
    "level": "Level",
    "grade": "Level",
    
    # AD ID
    "ad_id": "AdId",
    "ad id": "AdId",
    "active directory": "AdId",
    "domain id": "AdId",
    
    # Dates
    "tcs_doj": "TcsDoj",
    "tcs doj": "TcsDoj",
    "tcs joining": "TcsDoj",
    "sbi_doj": "SbiDoj",
    "sbi doj": "SbiDoj",
    "sbi joining": "SbiDoj",
    "onboarded": "OnboardedOn",
    "onboarded on": "OnboardedOn",
    "onboarding date": "OnboardedOn",
    
    # Company
    "company": "BACompany",
    "ba company": "BACompany",
    "business area": "BACompany",
    
    # Cards and IDs
    "id card": "IdCard",
    "access card": "AccessCard",
    "card": "AccessCard",
}

# Question patterns for better understanding
QUESTION_PATTERNS = {
    "count": [r"\bhow many\b", r"\bcount\b", r"\bnumber of\b", r"\btotal\b"],
    "exists": [r"\bis there\b", r"\bare there\b", r"\bdo we have\b", r"\bdoes\b"],
    "list": [r"\blist\b", r"\bshow\b", r"\bfind\b", r"\bget\b", r"\btell me\b"],
    "specific": [r"\bwhat is\b", r"\bwho is\b", r"\bwhere is\b", r"\bwhich\b"],
    "compare": [r"\bcompare\b", r"\bdifference\b", r"\bversus\b", r"\bvs\b"],
}

# Context-aware configuration
CONTEXT_CONFIG = {
    "max_history_items": 10,
    "context_expiry_minutes": 30,
    "similarity_threshold": 0.7,
    "cache_size": 100,
}

# Blocked patterns for security
BLOCKED_PATTERNS = [
    r"\brm\b", r"\bkill\b", r"\breboot\b", r"\bshutdown\b", r"\buserdel\b",
    r"\bpasswd\b", r"\bmkfs\b", r"\bwget\b", r"\bcurl\b", r":\s*(){:|:&};:",
    r"\bsudo\b", r"\bsu\b", r"\bchmod\b", r"\bchown\b", r"\bdd\b",
    r"\bmount\s+/", r"\bumount\b", r"\bfdisk\b", r"\bparted\b", r"\bmkfs\b",
    r"\biptables\b", r"\bufw\b", r"\bfirewall\b", r"\bselinux\b"
]

# Sensitive fields that should never be included in queries or results
SENSITIVE_FIELDS = ["Pwd", "SecQ", "SecA"]

# Setup logging
logging.basicConfig(
    filename=os.path.expanduser("~/.team_details_ai.log"),
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class QueryCache:
    """Simple query cache to improve response time"""
    def __init__(self, max_size: int = 100):
        self.cache = {}
        self.access_times = {}
        self.max_size = max_size
    
    def _generate_key(self, query: str) -> str:
        """Generate cache key from query"""
        return hashlib.md5(query.lower().strip().encode()).hexdigest()
    
    def get(self, query: str) -> Optional[Dict]:
        """Get cached result if exists and not expired"""
        key = self._generate_key(query)
        if key in self.cache:
            if datetime.now() - self.access_times[key] < timedelta(minutes=5):
                self.access_times[key] = datetime.now()
                logger.info(f"Cache hit for query: {query[:50]}...")
                return self.cache[key]
            else:
                del self.cache[key]
                del self.access_times[key]
        return None
    
    def set(self, query: str, result: Dict):
        """Cache query result"""
        key = self._generate_key(query)
        
        if len(self.cache) >= self.max_size:
            oldest_key = min(self.access_times.keys(), key=lambda k: self.access_times[k])
            del self.cache[oldest_key]
            del self.access_times[oldest_key]
        
        self.cache[key] = result
        self.access_times[key] = datetime.now()
        logger.info(f"Cached result for query: {query[:50]}...")

class QueryClassifier:
    """Classifies queries as simple or complex with better accuracy"""
    
    @staticmethod
    def is_simple_query(query: str) -> Tuple[bool, str]:
        """
        Determine if query is simple (just name/uid) or complex
        Returns: (is_simple, query_type)
        """
        query = query.strip()
        
        # Check if it's just a UID (4-8 digits)
        if re.match(r'^\d{4,8}$', query):
            return True, "uid"
        
        # Check if it's just an email
        if re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$', query):
            return True, "email"
        
        # Check if it's just a name (1-4 words, all alphabetic with possible spaces/dots)
        if re.match(r'^[a-zA-Z.\s]{2,50}$', query) and len(query.split()) <= 4:
            # Additional check: no question words or complex patterns
            question_words = ['what', 'who', 'where', 'when', 'why', 'how', 'is', 'are', 'can', 'do', 'does', 'tell', 'show', 'find', 'get', 'list', 'count', 'many']
            query_lower = query.lower()
            
            if not any(word in query_lower for word in question_words):
                return True, "name"
        
        # Everything else is complex
        return False, "complex"

def is_dangerous(text: str) -> bool:
    """Check if text contains dangerous patterns"""
    return any(re.search(pattern, text.lower()) for pattern in BLOCKED_PATTERNS)

def enhance_question_understanding(question: str) -> str:
    """Enhanced question preprocessing with better field mapping"""
    enhanced_question = question.lower().strip()
    
    # Apply field mappings with word boundary checks
    for term, field in FIELD_MAPPINGS.items():
        # Use word boundaries to avoid partial matches
        pattern = r'\b' + re.escape(term.lower()) + r'\b'
        enhanced_question = re.sub(pattern, field, enhanced_question)
    
    return enhanced_question

def clean_and_fix_sql(raw_sql: str, original_question: str = "") -> str:
    """Enhanced SQL cleaning with better pattern recognition and column validation"""
    logger.info(f"Raw SQL input: {repr(raw_sql)}")
    
    # Handle case where LLM returns descriptive text instead of SQL
    if "select" not in raw_sql.lower() and any(word in raw_sql.lower() for word in ["uid", "employee", "name", "team"]):
        # Try to extract meaningful parts
        uid_match = re.search(r'\b(\d{4,8})\b', raw_sql)
        name_match = re.search(r'\b([A-Z][a-z]+(?: [A-Z][a-z]+)*)\b', original_question)
        email_match = re.search(r'\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}\b', original_question)
        team_match = re.search(r'\b(iib|team|department|group)\b', original_question.lower())
        
        if uid_match:
            uid = uid_match.group(1)
            return f"SELECT Uid, EmpName, Project, Team, Contact, TcsEmail, SbiEmail, AdId, Position, Level, BACompany FROM UserMaster WHERE Uid = {uid}"
        elif email_match:
            email = email_match.group(0)
            return f"SELECT Uid, EmpName, Project, Team, Contact, TcsEmail, SbiEmail, AdId, Position, Level, BACompany FROM UserMaster WHERE TcsEmail LIKE '%{email}%' OR SbiEmail LIKE '%{email}%'"
        elif name_match:
            name = name_match.group(0)
            return f"SELECT Uid, EmpName, Project, Team, Contact, TcsEmail, SbiEmail, AdId, Position, Level, BACompany FROM UserMaster WHERE EmpName LIKE '%{name}%'"
        elif team_match:
            # Handle team queries specifically
            team_name = re.search(r'\b(iib|team|department|group)\s+([A-Za-z0-9]+)', original_question.lower())
            if team_name:
                return f"SELECT Uid, EmpName, Team, Position FROM UserMaster WHERE Team LIKE '%{team_name.group(2)}%'"
            return f"SELECT COUNT(*) as count FROM UserMaster WHERE Team LIKE '%iib%'"

    # Extract SQL from code block if present
    match = re.search(r"```sql\s*(.*?)\s*```", raw_sql, re.DOTALL | re.IGNORECASE)
    if match:
        sql = match.group(1).strip()
    else:
        # Look for SELECT statement
        sql = re.sub(r"```", "", raw_sql)
        select_match = re.search(r"(SELECT.*?)(?:\n|$|;)", sql, re.IGNORECASE | re.DOTALL)
        if select_match:
            sql = select_match.group(1).strip()
        else:
            # Try to find any SELECT statement
            select_start = sql.lower().find('select')
            if select_start != -1:
                sql = sql[select_start:].strip()
            else:
                return raw_sql

    # Remove sensitive fields from SELECT clause
    for field in SENSITIVE_FIELDS:
        # Remove from SELECT list
        sql = re.sub(rf'\b{field}\b\s*,?\s*', '', sql, flags=re.IGNORECASE)
        sql = re.sub(rf',\s*\b{field}\b', '', sql, flags=re.IGNORECASE)
        # Remove from WHERE clause
        sql = re.sub(rf'\bWHERE\s+\b{field}\b[^A-Z]*?(?=\s+(AND|OR|ORDER|GROUP|LIMIT|$))', 'WHERE ', sql, flags=re.IGNORECASE)
        sql = re.sub(rf'\b(AND|OR)\s+\b{field}\b[^A-Z]*?(?=\s+(AND|OR|ORDER|GROUP|LIMIT|$))', '', sql, flags=re.IGNORECASE)

    # Clean up SQL syntax
    sql = re.sub(r',\s*,', ',', sql)  # Remove double commas
    sql = re.sub(r'SELECT\s*,', 'SELECT ', sql, flags=re.IGNORECASE)  # Fix SELECT ,
    sql = re.sub(r',\s*FROM', ' FROM', sql, flags=re.IGNORECASE)  # Fix , FROM
    sql = re.sub(r'WHERE\s+AND', 'WHERE', sql, flags=re.IGNORECASE)  # Fix WHERE AND
    sql = re.sub(r'WHERE\s+OR', 'WHERE', sql, flags=re.IGNORECASE)  # Fix WHERE OR
    sql = re.sub(r'WHERE\s*$', '', sql, flags=re.IGNORECASE)  # Remove empty WHERE

    # Improve text field matching - use LIKE instead of exact match
    text_fields = ['EmpName', 'Contact', 'TcsEmail', 'SbiEmail', 'AdId', 'Position', 'Level', 'Team', 'Project', 'BACompany']
    for field in text_fields:
        # Convert = to LIKE for text fields
        sql = re.sub(f"({field})\\s*=\\s*'([^']*)'", f"\\1 LIKE '%\\2%'", sql, flags=re.IGNORECASE)
        sql = re.sub(f'({field})\\s*=\\s*"([^"]*)"', f"\\1 LIKE '%\\2%'", sql, flags=re.IGNORECASE)

    # Special handling for team queries
    if 'team' in original_question.lower() or 'department' in original_question.lower():
        # Ensure we're searching in the Team column
        sql = re.sub(r'\b(where|and|or)\s+[a-zA-Z]+\s+like\s+\'%iib%\'', 
                    r"\1 Team LIKE '%iib%'", sql, flags=re.IGNORECASE)

    sql = sql.strip().rstrip(";")

    # Add reasonable limit if none exists and it's not a COUNT query
    if not re.search(r"\bLIMIT\b", sql, re.IGNORECASE) and not re.search(r"\bCOUNT\s*\(", sql, re.IGNORECASE):
        sql += " LIMIT 50"

    logger.info(f"Final cleaned SQL: {sql}")
    return sql

def is_select_query(sql: str) -> bool:
    """Check if query is a safe SELECT query"""
    sql_clean = sql.strip().lower()
    starts_with_select = sql_clean.startswith('select')
    has_dangerous_ops = any(kw in sql_clean for kw in ['insert', 'update', 'delete', 'drop', 'alter', 'create', 'truncate'])
    
    return starts_with_select and not has_dangerous_ops

class EnhancedTeamDetailsAssistant:
    def __init__(self):
        self.llm = None
        self.db_handler = None
        self.initialized = False
        self.cache = QueryCache(max_size=CONTEXT_CONFIG['cache_size'])
        self.classifier = QueryClassifier()

    def initialize(self):
        """Initialize the Team Details Assistant with optimizations"""
        try:
            # Initialize LLM with optimized settings
            self.llm = OllamaLLM(
                model="myllm:latest", 
                temperature=0.1,
                request_timeout=45.0
            )

            # Set up database connection
            db_cfg = TEAM_DB_CONFIG['db_config']
            uri = f"mysql+pymysql://{db_cfg['user']}:{db_cfg['password']}@{db_cfg['host']}/{db_cfg['database']}"

            db_for_llm = SQLDatabase.from_uri(
                uri,
                include_tables=TEAM_DB_CONFIG.get("include_tables"),
                engine_args={
                    "pool_pre_ping": True,
                    "pool_recycle": 1800,
                    "pool_size": 5,
                    "max_overflow": 10,
                    "connect_args": {
                        "connect_timeout": 15,
                        "charset": "utf8mb4"
                    }
                }
            )

            chain = create_sql_query_chain(self.llm, db_for_llm)

            # Create direct connection for executing queries
            db_conn = pymysql.connect(
                host=db_cfg['host'],
                user=db_cfg['user'],
                password=db_cfg['password'],
                database=db_cfg['database'],
                charset='utf8mb4',
                cursorclass=pymysql.cursors.DictCursor,
                autocommit=True,
                connect_timeout=15
            )

            self.db_handler = {
                'chain': chain,
                'connection': db_conn,
                'config': TEAM_DB_CONFIG
            }

            self.initialized = True
            logger.info("Enhanced Team Details Assistant initialized successfully")
            return True

        except Exception as e:
            logger.error(f"Initialization failed: {e}\n{traceback.format_exc()}")
            return False

    def execute_simple_query(self, query: str, query_type: str) -> Dict:
        """Execute simple query without AI (direct SQL)"""
        try:
            if query_type == "uid":
                uid = query.strip()
                sql = f"SELECT Uid, EmpName, Project, Team, Contact, TcsEmail, SbiEmail, AdId, Position, Level, TcsDoj, SbiDoj, BACompany, OnboardedOn FROM UserMaster WHERE Uid = {uid}"
                
            elif query_type == "email":
                email = query.strip()
                sql = f"SELECT Uid, EmpName, Project, Team, Contact, TcsEmail, SbiEmail, AdId, Position, Level, TcsDoj, SbiDoj, BACompany FROM UserMaster WHERE TcsEmail LIKE '%{email}%' OR SbiEmail LIKE '%{email}%' LIMIT 10"
                
            elif query_type == "name":
                name = query.strip()
                sql = f"SELECT Uid, EmpName, Project, Team, Contact, TcsEmail, SbiEmail, AdId, Position, Level, TcsDoj, SbiDoj, BACompany FROM UserMaster WHERE EmpName LIKE '%{name}%' LIMIT 10"
            
            else:
                return {"error": "Unknown simple query type"}

            logger.info(f"Executing simple query - SQL: {sql}")
            
            with self.db_handler['connection'].cursor() as cursor:
                cursor.execute(sql)
                result = cursor.fetchall()
                
                return {
                    "query_type": "simple",
                    "original_query": query,
                    "sql_used": sql,
                    "result": result,
                    "result_count": len(result)
                }
                
        except Exception as e:
            logger.error(f"Simple query execution error: {e}")
            return {"error": f"Database error: {str(e)}"}

    def execute_complex_query(self, query: str) -> Dict:
        """Execute complex query using AI with enhanced understanding"""
        try:
            # Check cache first
            cached_result = self.cache.get(query)
            if cached_result:
                return cached_result

            # Enhanced question preprocessing
            processed_question = enhance_question_understanding(query)
            
            # Determine question type for better prompting
            question_type = "general"
            for qtype, patterns in QUESTION_PATTERNS.items():
                if any(re.search(pattern, query.lower()) for pattern in patterns):
                    question_type = qtype
                    break

            # Create comprehensive database schema context
            schema_context = """
            TABLE: UserMaster
            COLUMNS:
            - Uid (int): Employee ID (Primary Key)
            - EmpName (varchar): Employee Name
            - Project (varchar): Project Name
            - Team (varchar): Team Name
            - Contact (varchar): Phone Number (11 digits)
            - TcsEmail (varchar): TCS Email Address
            - SbiEmail (varchar): SBI Email Address  
            - AdId (varchar): Active Directory ID
            - Position (varchar): Job Position/Designation
            - Level (varchar): Employee Level/Grade
            - TcsDoj (varchar): TCS Date of Joining
            - SbiDoj (varchar): SBI Date of Joining
            - BACompany (varchar): Business Area Company
            - OnboardedOn (date): Onboarding Date
            - IdCard, AccessCard, PvcAppId: Various ID cards/applications
            - Rid, Tid, Enable, Mandatory, SuperLevel: System fields
            
            NEVER include: Pwd, SecQ, SecA (sensitive fields)
            """

            # Enhanced prompt based on question type
            if question_type == "count":
                final_question = f"""
{schema_context}

Question: {processed_question}

Generate a SQL query to count records matching the criteria. 
For team counts, use: SELECT COUNT(*) FROM UserMaster WHERE Team LIKE '%team_name%'
For project counts, use: SELECT COUNT(*) FROM UserMaster WHERE Project LIKE '%project_name%'
Always search in the correct column based on the question.
"""
            elif question_type == "exists":
                final_question = f"""
{schema_context}

Question: {processed_question}

Generate a SQL query to check existence. For team-related questions, 
make sure to search in the Team column: 
SELECT COUNT(*) FROM UserMaster WHERE Team LIKE '%team_name%' AND other_conditions
"""
            elif question_type == "list":
                final_question = f"""
{schema_context}

Question: {processed_question}

Generate a SQL query to list records. For team-related queries, 
use: SELECT Uid, EmpName, Team, Position FROM UserMaster WHERE Team LIKE '%team_name%'
"""
            else:
                final_question = f"""
{schema_context}

Question: {processed_question}

Generate an appropriate SQL SELECT query based on the question.
- For team questions, search in Team column: Team LIKE '%value%'
- For project questions, search in Project column
- Use LIKE for text matching
- Select only relevant columns
- Add appropriate WHERE conditions
- Use LIMIT for large result sets
"""

            # Generate SQL query using AI
            start_time = datetime.now()
            raw_sql = self.db_handler['chain'].invoke({"question": final_question})
            generation_time = (datetime.now() - start_time).total_seconds()
            
            logger.info(f"SQL generation took {generation_time:.2f} seconds")
            logger.info(f"Generated raw SQL: {raw_sql}")

            # Clean and validate SQL
            sql = clean_and_fix_sql(raw_sql, query)

            if not is_select_query(sql):
                return {"error": "Invalid query generated. Only SELECT queries are allowed."}

            # Security check for sensitive fields
            for sensitive_field in SENSITIVE_FIELDS:
                if sensitive_field.lower() in sql.lower():
                    logger.warning(f"Blocked query containing sensitive field: {sensitive_field}")
                    return {"error": "Cannot access sensitive information. Please rephrase your query."}

            # Execute query
            with self.db_handler['connection'].cursor() as cursor:
                execution_start = datetime.now()
                cursor.execute(sql)
                result = cursor.fetchall()
                execution_time = (datetime.now() - execution_start).total_seconds()
                
                logger.info(f"Query execution took {execution_time:.2f} seconds, returned {len(result)} rows")

                query_result = {
                    "query_type": "complex",
                    "question_type": question_type,
                    "original_query": query,
                    "sql_used": sql,
                    "result": result,
                    "result_count": len(result),
                    "generation_time": generation_time,
                    "execution_time": execution_time
                }

                # Cache the result
                self.cache.set(query, query_result)
                return query_result

        except Exception as e:
            logger.error(f"Complex query execution error: {e}")
            return {"error": f"Query processing error: {str(e)}"}

    def analyze_results_with_ai(self, query_result: Dict, original_question: str) -> str:
        """Enhanced AI analysis with better context understanding"""
        try:
            if "error" in query_result:
                return f"❌ {query_result['error']}"

            result = query_result["result"]
            question_type = query_result.get("question_type", "general")
            
            if not result:
                if question_type == "exists":
                    return "❌ **Answer: NO** - No employees found matching your criteria."
                elif question_type == "count":
                    return "📊 **Answer: 0** - No employees found matching your criteria."
                else:
                    return "❌ No records found matching your criteria."

            # Enhanced analysis prompt based on question type
            if question_type == "count":
                if len(result) == 1 and 'COUNT(*)' in str(result[0]) or any('count' in str(k).lower() for k in result[0].keys()):
                    count_value = list(result[0].values())[0]
                    analysis_prompt = f"""
Original Question: "{original_question}"
SQL Query Used: {query_result["sql_used"]}
Count Result: {count_value}

Provide a clear, direct answer starting with the number. 
Format: "📊 **Answer: {count_value}** - [brief explanation]"
Be specific about what was counted.
"""
                else:
                    analysis_prompt = f"""
Original Question: "{original_question}"
SQL Query Used: {query_result["sql_used"]}
Results Count: {len(result)}

The query returned {len(result)} records instead of a count. 
Provide the count and brief summary of what was found.
Format: "📊 **Answer: {len(result)}** - [brief explanation]"
"""

            elif question_type == "exists":
                analysis_prompt = f"""
Original Question: "{original_question}"
SQL Query Used: {query_result["sql_used"]}
Results Found: {len(result)} records

This is a yes/no question. Provide a clear YES or NO answer.
Format: "✅ **Answer: YES** - [brief explanation]" or "❌ **Answer: NO** - [brief explanation]"
If records found, answer YES with details. If no records, answer NO.
"""

            else:
                # Prepare result summary for analysis
                result_summary = []
                for i, record in enumerate(result[:5]):  # Show first 5 for analysis
                    summary = {}
                    if 'Uid' in record and record['Uid']: 
                        summary['ID'] = record['Uid']
                    if 'EmpName' in record and record['EmpName']: 
                        summary['Name'] = record['EmpName']
                    if 'Team' in record and record['Team']: 
                        summary['Team'] = record['Team']
                    if 'Project' in record and record['Project']: 
                        summary['Project'] = record['Project']
                    if 'Position' in record and record['Position']: 
                        summary['Position'] = record['Position']
                    if 'TcsEmail' in record and record['TcsEmail']: 
                        summary['Email'] = record['TcsEmail']
                    result_summary.append(summary)

                analysis_prompt = f"""
Original Question: "{original_question}"
SQL Query Used: {query_result["sql_used"]}
Number of Results: {len(result)}

Sample Results (first 5):
{json.dumps(result_summary, indent=2)}

Provide a natural language response that:
1. Directly answers the user's question
2. Includes specific details when relevant
3. Uses a conversational, helpful tone
4. Summarizes multiple results effectively
5. Highlights the most important information

If showing employee details, format clearly with emojis:
🆔 ID: [employee_id]
👤 Name: [name]
👥 Team: [team]
📂 Project: [project]
💼 Position: [position]
📧 Email: [email]
"""

            # Get AI analysis
            analysis_start = datetime.now()
            ai_response = self.llm.invoke(analysis_prompt)
            analysis_time = (datetime.now() - analysis_start).total_seconds()
            
            logger.info(f"AI analysis took {analysis_time:.2f} seconds")
            
            return ai_response.strip()

        except Exception as e:
            logger.error(f"AI analysis error: {e}")
            # Enhanced fallback formatting
            return self._format_results_enhanced(query_result, original_question)

    def _format_results_enhanced(self, query_result: Dict, original_question: str) -> str:
        """Enhanced basic result formatting as fallback"""
        result = query_result["result"]
        question_type = query_result.get("question_type", "general")
        
        if question_type == "count":
            if len(result) == 1 and any('count' in str(k).lower() for k in result[0].keys()):
                count_value = list(result[0].values())[0]
                return f"📊 **Answer: {count_value}** employees found matching your criteria."
            else:
                return f"📊 **Answer: {len(result)}** employees found matching your criteria."
        
        elif question_type == "exists":
            if len(result) > 0:
                return f"✅ **Answer: YES** - Found {len(result)} employee(s) matching your criteria."
            else:
                return f"❌ **Answer: NO** - No employees found matching your criteria."
        
        elif len(result) == 1:
            record = result[0]
            response = "🔍 **Found 1 employee:**\n\n"
            if 'Uid' in record and record['Uid']:
                response += f"🆔 Employee ID: {record['Uid']}\n"
            if 'EmpName' in record and record['EmpName']:
                response += f"👤 Name: {record['EmpName']}\n"
            if 'Team' in record and record['Team']:
                response += f"👥 Team: {record['Team']}\n"
            if 'Project' in record and record['Project']:
                response += f"📂 Project: {record['Project']}\n"
            if 'Position' in record and record['Position']:
                response += f"💼 Position: {record['Position']}\n"
            if 'Contact' in record:
                response += f"📞 Contact: {record['Contact']}\n"
            return response.strip()
        else:
            return f"Found {len(result)} employees matching your criteria."

    def process_question(self, question: str) -> str:
        """Main processing function that handles both simple and complex queries"""
        if not self.initialized and not self.initialize():
            return "❌ Team Details Assistant initialization failed."

        if is_dangerous(question):
            return "❌ Question blocked for security reasons."

        start_time = datetime.now()

        # Classify query
        is_simple, query_type = self.classifier.is_simple_query(question)
        
        logger.info(f"Query classified as: {'Simple' if is_simple else 'Complex'} ({query_type})")

        # Execute appropriate query type
        if is_simple:
            query_result = self.execute_simple_query(question, query_type)
        else:
            query_result = self.execute_complex_query(question)

        # For complex queries, use AI to analyze results
        if not is_simple and "error" not in query_result:
            ai_response = self.analyze_results_with_ai(query_result, question)
            
            # Create detailed response with explanation
            response = f"🤖 **AI Analysis:**\n{ai_response}\n\n"
            response += f"📊 **Query Details:**\n"
            response += f"• Query Type: Complex (AI-generated)\n"
            response += f"• SQL Used: `{query_result['sql_used']}`\n"
            response += f"• Results Found: {query_result['result_count']}\n"
            if 'generation_time' in query_result:
                response += f"• Generation Time: {query_result['generation_time']:.2f}s\n"
            if 'execution_time' in query_result:
                response += f"• Execution Time: {query_result['execution_time']:.2f}s"

        else:
            # For simple queries, provide direct results
            if "error" in query_result:
                response = f"❌ {query_result['error']}"
            else:
                response = self._format_results_enhanced(query_result, question)
                response += f"\n\n📊 **Query Details:**\n"
                response += f"• Query Type: Simple (Direct SQL)\n"
                response += f"• SQL Used: `{query_result['sql_used']}`\n"
                response += f"• Results Found: {query_result['result_count']}"

        total_time = (datetime.now() - start_time).total_seconds()
        response += f"\n• Total Time: {total_time:.2f}s"
        
        logger.info(f"Total processing time: {total_time:.2f} seconds")
        return response

def Teammain(query: str) -> str:
    """Enhanced main function with simple/complex query handling"""
    logger.info("🚀 Starting Enhanced Team Details Assistant...")
    
    assistant = EnhancedTeamDetailsAssistant()
    result = assistant.process_question(query)
    
    logger.info("✅ Query processing complete.")
    return result

# Example usage and testing
if __name__ == "__main__":
    # Test different query types
    test_queries = [
        "1234567",  # Simple UID query
        "John Smith",  # Simple name query  
        "What is the team of employee 1234567?",  # Complex query
        "How many people are in IIB team?",  # Team count query
        "Are there any employees named John in the QA team?",  # Complex query
        "Show me all managers in the project Alpha",  # Complex query
    ]

    assistant = EnhancedTeamDetailsAssistant()
    
    for query in test_queries:
        print(f"\n{'='*80}")
        print(f"Query: {query}")
        is_simple, query_type = assistant.classifier.is_simple_query(query)
        print(f"Classification: {'Simple' if is_simple else 'Complex'} ({query_type})")
        print('='*80)
        result = assistant.process_question(query)
        print(result)
