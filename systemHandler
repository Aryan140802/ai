import os
import re
import logging
import subprocess
import pymysql
import traceback
from typing import List, Optional, Dict, Any
from datetime import datetime
import json

from langchain_community.utilities import SQLDatabase
from langchain_ollama import OllamaLLM
from langchain.chains import create_sql_query_chain

class SystemReportAnalyzer:
    def __init__(self):
        self.llm = None
        self.report_content = ""
        self.chat_history = []
        
    def initialize_llm(self):
        """Initialize the Ollama LLM connection"""
        try:
            self.llm = OllamaLLM(model="myllm:latest", temperature=0.1)
            logger.info("Connected to LLM model: myllm:latest")
            return True
        except Exception as e:
            logger.error(f"Failed to connect to LLM: {str(e)}")
            return False
    
    def load_report(self, report_path: str):
        """Load the system report from a file"""
        try:
            with open(report_path, 'r') as f:
                self.report_content = f.read()
            logger.info(f"Successfully loaded report from {report_path}")
            return True
        except Exception as e:
            logger.error(f"Failed to load report: {str(e)}")
            return False
    
    def analyze_report(self, question: str) -> str:
        """Analyze the report content using the LLM"""
        if not self.llm:
            return "LLM not initialized. Please connect first."
        
        if not self.report_content:
            return "No report loaded. Please load a report first."
        
        try:
            # Create a prompt with the report context
            prompt = f"""
            System Report Analysis:
            
            Below is a system report from a Red Hat Enterprise Linux server:
            {self.report_content[:10000]}... [truncated if too long]
            
            Question: {question}
            
            Please analyze the report and provide:
            1. A concise answer to the question
            2. Relevant metrics from the report
            3. Any concerning findings
            4. Recommendations if issues are found
            
            Answer in clear, professional language suitable for a sysadmin.
            """
            
            # Get response directly from LLM
            response = self.llm(prompt)
            
            # Clean up the response
            cleaned_response = response.strip()
            
            # Save to chat history
            self.chat_history.append({
                "user": question,
                "assistant": cleaned_response
            })
            
            return cleaned_response
        
        except Exception as e:
            logger.error(f"Analysis failed: {str(e)}")
            return f"Error analyzing report: {str(e)}"
    
    def interactive_session(self):
        """Start an interactive terminal session"""
        print("\n" + "="*50)
        print("System Report Analyzer")
        print("="*50 + "\n")
        
        # Initialize LLM
        if not self.initialize_llm():
            print("Failed to initialize LLM. Exiting.")
            return
        
        # Load report
        report_path = input("Enter path to system report file: ").strip()
        if not self.load_report(report_path):
            print("Failed to load report. Exiting.")
            return
        
        print("\nSystem report loaded successfully.")
        print("Type 'exit' to quit the session.\n")
        
        # Main interaction loop
        while True:
            try:
                question = input("Your question about the system report: ").strip()
                
                if question.lower() in ['exit', 'quit']:
                    print("Exiting...")
                    break
                    
                if not question:
                    print("Please enter a question.")
                    continue
                
                if question.lower() == 'help':
                    self.show_help()
                    continue
                
                print("\nAnalyzing...\n")
                response = self.analyze_report(question)
                print("\nAnalysis Result:")
                print("-"*50)
                print(response)
                print("-"*50 + "\n")
                
            except KeyboardInterrupt:
                print("\nExiting...")
                break
            except Exception as e:
                logger.error(f"Error during interaction: {str(e)}")
                print(f"An error occurred: {str(e)}")
    
    def show_help(self):
        """Display help information"""
        help_text = """
SYSTEM REPORT ANALYZER HELP

You can ask questions about:

System Overview:
- What's the system uptime?
- Show OS version details
- What's the kernel version?

Resource Usage:
- What's the current CPU utilization?
- Show memory usage breakdown
- What processes are using the most CPU?
- Are there any zombie processes?

Storage:
- What's the disk usage situation?
- Which partitions are nearly full?
- Show largest directories

Services:
- List all running services
- Are there any failed services?
- Show status of specific service

Network:
- Show open network ports
- What's the network configuration?
- List active connections

Security:
- Is SELinux enabled?
- Show firewall status
- List security services running

Commands:
- help: Show this help
- exit: Quit the analyzer
"""
        print(help_text)

def main():
    # Configure logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    logger = logging.getLogger(__name__)
    
    analyzer = SystemReportAnalyzer()
    analyzer.interactive_session()

if __name__ == "__main__":
    main()
