#!/usr/bin/env python3
import os
import re
from datetime import datetime
from langchain_ollama import OllamaLLM
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

class SystemAnalyzer:
    def __init__(self):
        self.llm = OllamaLLM(model="myllm:latest", temperature=0.1)
        self.analysis_history = []
        
    def load_system_report(self, file_path):
        """Load the system report from file"""
        try:
            with open(file_path, 'r') as f:
                return f.read()
        except Exception as e:
            return f"Error loading report: {e}"

    def analyze_system(self, report_text, question):
        """Analyze the system report and answer questions"""
        prompt_template = PromptTemplate(
            input_variables=["report", "question"],
            template="""
            You are a Red Hat Enterprise Linux system administrator assistant. Analyze the following system report and provide detailed answers to the user's questions.
            Focus on identifying issues, performance bottlenecks, security concerns, and provide actionable recommendations.

            SYSTEM REPORT:
            {report}

            USER QUESTION: {question}

            Provide your analysis in this format:
            1. [Key Observation] - Brief description of what you found
            2. [Impact] - How this affects system performance/security
            3. [Recommendation] - Suggested actions to take
            4. [Additional Info] - Any other relevant details

            Answer concisely but thoroughly, using your Linux administration expertise.
            """
        )
        
        chain = LLMChain(llm=self.llm, prompt=prompt_template)
        response = chain.run(report=report_text, question=question)
        
        # Store the analysis in history
        self.analysis_history.append({
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "question": question,
            "response": response
        })
        
        return response

    def interactive_session(self, report_file):
        """Start an interactive Q&A session about the system"""
        print("Loading system report...")
        report = self.load_system_report(report_file)
        
        if report.startswith("Error"):
            print(report)
            return
            
        print("\nSystem Analyzer ready. Ask questions about your Red Hat system or type 'exit' to quit.")
        print("Example questions:")
        print("- What's causing the high load average?")
        print("- Are there any security concerns I should address?")
        print("- Which processes are consuming the most resources?")
        print("- Is there enough free disk space?")
        
        while True:
            try:
                question = input("\nYour question: ").strip()
                if not question:
                    continue
                    
                if question.lower() in ['exit', 'quit', 'q']:
                    break
                
                print("\nAnalyzing...\n")
                response = self.analyze_system(report, question)
                print(response)
                
            except KeyboardInterrupt:
                print("\nExiting...")
                break
            except Exception as e:
                print(f"\nError: {e}")

if __name__ == "__main__":
    analyzer = SystemAnalyzer()
    
    # Specify the path to your system report file
    report_file = "rhel_system_report_20250723_165647.txt"  # Update this path
    
    # Start interactive session
    analyzer.interactive_session(report_file)
